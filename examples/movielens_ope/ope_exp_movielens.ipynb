{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jAwux6YPtW5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from rs_datasets import MovieLens\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pyspark.sql import functions as sf, types as st\n",
    "from pyspark.sql.types import IntegerType\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from replay.utils.spark_utils import convert2spark\n",
    "from replay.experimental.scenarios.movielens_wrapper.replay_offline import OBPOfflinePolicyLearner\n",
    "from replay.experimental.scenarios.movielens_wrapper.utils import get_est_rewards_by_reg, bandit_subset\n",
    "\n",
    "from replay.models import UCB, RandomRec, LinUCB\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from obp.ope import (\n",
    "    OffPolicyEvaluation,\n",
    "    DirectMethod,\n",
    "    InverseProbabilityWeighting,\n",
    "    SelfNormalizedInverseProbabilityWeighting,\n",
    "    SelfNormalizedDoublyRobust,\n",
    ")\n",
    "\n",
    "from replay.experimental.scenarios.offpolicy.modified_ips import Exp_Smooth_IPS_Min, Exp_Smooth_IPS_Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7w322FNw3yrn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = MovieLens(\"1m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1udmcuQc4DC-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_ITEMS = 1500\n",
    "N_USERS = 600\n",
    "name_dir = 'out_exp' #name of the directory to save the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.ratings['timestamp'] = pd.to_datetime(data.ratings['timestamp'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KWpggomA4_er",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logs = data.ratings.copy()\n",
    "logs['cnt'] = 1\n",
    "logs = logs[['item_id', 'cnt']].groupby(by=[\"item_id\"]).sum()\n",
    "logs = logs.sort_values(by=['cnt'], ascending=False).reset_index()\n",
    "popular_items = logs.iloc[:N_ITEMS]['item_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cXPTYlj5ECT",
    "outputId": "bf3ac412-44a3-4f22-dd59-ff97e03c46e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.ratings = data.ratings[data.ratings['item_id'].isin(popular_items)]\n",
    "print('размер датасета логов после выброса непопулярных айтемов:', data.ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhSpiQi05ZXq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "logs = data.ratings.copy()\n",
    "logs['cnt'] = 1\n",
    "logs = logs[['user_id', 'cnt']].groupby(by=[\"user_id\"]).sum()\n",
    "logs = logs.sort_values(by=['cnt'], ascending=False).reset_index()\n",
    "popular_users = logs.iloc[:N_USERS]['user_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IYQh7Q4V5ZaJ",
    "outputId": "c6332e1a-af11-4cad-b408-7b0d3623563d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.ratings = data.ratings[data.ratings['user_id'].isin(popular_users)]\n",
    "print('размер датасета логов после выброса непопулярных юзеров:', data.ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PM_iKvFu5GXd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "items = set(data.ratings['item_id'].tolist())\n",
    "users = set(data.ratings['user_id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DyToOBX45QNl",
    "outputId": "654062f4-2560-48d8-ef37-80f169df47d6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.items = data.items[data.items['item_id'].isin(items)]\n",
    "data.users = data.users[data.users['user_id'].isin(users)]\n",
    "data.users.shape, data.items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "gHw8UQDnhNvZ",
    "outputId": "76173789-9a06-46da-cc2b-6ab16d243a93",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKjxdf9Jd3Iz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def features_svd(log, user_features, rank, item_id='item_id', user_id='user_id'):\n",
    "\n",
    "    interaction_matrix = csr_matrix(\n",
    "                                        (log['relevance'],\n",
    "                                        (log[user_id], log[item_id]), #subtract 1 to start with [0,1,2,...]\n",
    "                                    ),\n",
    "                                    shape=(N_USERS, N_ITEMS),\n",
    "                                    dtype=float)\n",
    "\n",
    "    u, singular_values, vh = svds(\n",
    "        interaction_matrix,\n",
    "        k=rank,\n",
    "    )\n",
    " \n",
    "    svd_feat = pd.DataFrame(np.c_[np.arange(N_USERS),u], columns=[user_id]+[f'svd_feat_{i}' for i in range(rank)])\n",
    "\n",
    "    return pd.merge(user_features, svd_feat, on=user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oguDNlN8hgu0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def frac_genres(log, user_features, item_features, item_id='item_id', user_id='user_id'):\n",
    "    merged = pd.merge(log, item_features, on=item_id)\n",
    "\n",
    "    # Суммируем жанры по пользователям\n",
    "    genre_counts = merged.groupby(user_id)[item_features.columns[1:]].sum()\n",
    "\n",
    "    # Считаем общее количество фильмов для каждого пользователя\n",
    "    total_movies = merged.groupby(user_id)[item_id].count()\n",
    "\n",
    "    # Вычисляем среднее количество фильмов для каждого жанра\n",
    "    average_genre_counts = genre_counts.div(total_movies, axis=0)\n",
    "\n",
    "    merged_user_features = pd.merge(user_features, average_genre_counts, on=user_id)\n",
    "    merged_user_features = merged_user_features.rename(columns = {name: name+'user' for name in item_features.drop(columns=[item_id]).columns.values})\n",
    "    return merged_user_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1WpMhWISH5O",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(data, item_features, user_features, item_id='item_id', user_id='user_id'):\n",
    "        # genres = (item_features.select(\"item_idx\", sf.split(\"genres\", \"\\|\").alias(\"genres\")))\n",
    "        # genres_list = (genres.select(sf.explode(\"genres\").alias(\"genre\")).distinct().filter('genre <> \"(no genres listed)\"').toPandas()[\"genre\"].tolist())\n",
    "        # item_features = genres\n",
    "        # for genre in genres_list:\n",
    "        #     item_features = item_features.withColumn(genre, sf.array_contains(sf.col(\"genres\"), genre).astype(IntegerType()))\n",
    "\n",
    "        # item_features = item_features.drop(\"genres\").cache()\n",
    "        item_features = item_features.drop(['title'], axis = 1)\n",
    "        item_features['genres'] = item_features['genres'].str.split('|')\n",
    "\n",
    "        genres_list = pd.Series([genre for sublist in item_features['genres'] for genre in sublist]).unique()\n",
    "        genres_list = [genre for genre in genres_list if genre != \"(no genres listed)\"]\n",
    "        for genre in genres_list:\n",
    "            item_features[genre] = item_features['genres'].apply(lambda x: int(genre in x))\n",
    "\n",
    "        item_features = item_features.drop(columns=['genres'])\n",
    "        item_features[item_id] = item_features[item_id].astype('int64')\n",
    "\n",
    "        user_features = user_features.drop(columns=['zip_code'])\n",
    "        bins = [0, 20, 30, 40, 50, 60, np.inf]\n",
    "        names = ['<20', '20-29', '30-39','40-49', '51-60', '60+']\n",
    "\n",
    "        user_features['agegroup'] = pd.cut(user_features['age'], bins, labels=names)\n",
    "        user_features = user_features.drop([\"age\"], axis = 1)\n",
    "\n",
    "        columnsToEncode = [\"agegroup\",\"gender\",\"occupation\"]\n",
    "\n",
    "        myEncoder = OneHotEncoder(sparse=False, handle_unknown='ignore') #for old versions use sparse\n",
    "        myEncoder.fit(user_features[columnsToEncode])\n",
    "\n",
    "        user_features = pd.concat([user_features.drop(columnsToEncode, 1),\n",
    "                           pd.DataFrame(myEncoder.transform(user_features[columnsToEncode]), \n",
    "                                        columns = myEncoder.get_feature_names_out(columnsToEncode))], axis=1).reindex()\n",
    "\n",
    "        user_features[user_id] = user_features[user_id].astype('int64')\n",
    "        user_features = frac_genres(data, user_features, item_features, item_id, user_id)\n",
    "\n",
    "        user_features =  features_svd(data, user_features, 16, item_id, user_id)\n",
    "        return item_features, user_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cMMV2YkMIRa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_items(data, features, item_id='item_id'):\n",
    "    \"\"\"Encode items to consecutive ids.\"\"\"\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    data[item_id] = encoder.fit_transform(data[item_id])\n",
    "    features[item_id] = encoder.transform(features[item_id])\n",
    "    return data, features\n",
    "\n",
    "\n",
    "def encode_users(data, features, user_id='user_id'):\n",
    "    \"\"\"Encode items to consecutive ids.\"\"\"\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    data[user_id] = encoder.fit_transform(data[user_id])\n",
    "    features[user_id] = encoder.transform(features[user_id])\n",
    "\n",
    "    return data, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQZMvivcOFZz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split(data, item_features, user_features, q, item_id='item_id', user_id='user_id'):\n",
    "    data['relevance'] = data['rating'].apply(lambda x: int(x>=3))\n",
    "    data = data.drop(['rating'], axis = 1)\n",
    "\n",
    "    test_timepoint = data['timestamp'].quantile(\n",
    "          q=q, interpolation='nearest'\n",
    "    )\n",
    "    test_data_ = data.query('timestamp >= @test_timepoint')\n",
    "\n",
    "    train_data_ = data.query(\n",
    "        'timestamp < @test_timepoint')\n",
    "    #drop cold items\n",
    "\n",
    "    test_data_ = test_data_[test_data_[item_id].isin(np.unique(train_data_[item_id].values))]\n",
    "    full_data  = data[data[item_id].isin(np.unique(train_data_[item_id].values))]\n",
    "    item_features = item_features[item_features[item_id].isin(np.unique(train_data_[item_id].values))]\n",
    "    #reindex items\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    full_data[item_id] = encoder.fit_transform(full_data[item_id])\n",
    "    test_data_[item_id] = encoder.transform(test_data_[item_id])\n",
    "    train_data_[item_id] = encoder.transform(train_data_[item_id])\n",
    "    item_features[item_id] = encoder.transform(item_features[item_id])\n",
    "\n",
    "    N_ITEMS = item_features.shape[0]\n",
    "\n",
    "    train_data_ = train_data_.sort_values('timestamp')\n",
    "    test_data_ = test_data_.sort_values('timestamp')\n",
    "    full_data = full_data.sort_values('timestamp')\n",
    "\n",
    "    user_features=user_features.reset_index(drop=True).sort_values(by = [user_id])\n",
    "    item_features=item_features.reset_index(drop=True).sort_values(by = [item_id])\n",
    "\n",
    "    return train_data_, test_data_, item_features, user_features, full_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4wwl-wxFRO7K",
    "tags": []
   },
   "outputs": [],
   "source": [
    "log, item_features = encode_items(data.ratings, data.items, item_id='item_id')\n",
    "log, user_features = encode_users(log, data.users, user_id='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQxQSrMcuLz4",
    "outputId": "d6d00380-c752-4c7f-abf5-9985f5dcd079",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test, item_features, user_features, post_log = split(log, item_features, user_features, q=0.7, item_id='item_id', user_id='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g7MUk0cJus_z",
    "outputId": "f1414891-9b24-4e42-9616-4b2fbb7d1c5a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_features, user_features = preprocess(post_log, item_features, user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.rename(columns={\"user_id\": \"user_idx\", \"item_id\": \"item_idx\"}, inplace=True)\n",
    "test.rename(columns={\"user_id\": \"user_idx\", \"item_id\": \"item_idx\"}, inplace=True)\n",
    "post_log.rename(columns={\"user_id\": \"user_idx\", \"item_id\": \"item_idx\"}, inplace=True)\n",
    "item_features.rename(columns={\"user_id\": \"user_idx\", \"item_id\": \"item_idx\"}, inplace=True)\n",
    "user_features.rename(columns={\"user_id\": \"user_idx\", \"item_id\": \"item_idx\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data in OBD format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bandit_feedback_train = dict(\n",
    "    log= convert2spark(train),\n",
    "    item_features= convert2spark(item_features),\n",
    "    user_features= convert2spark(user_features),\n",
    "    n_rounds= train.shape[0],\n",
    "    n_actions= item_features.shape[0],\n",
    "    action = train['item_idx'].values,\n",
    "    position= np.zeros(train.shape[0]).astype(np.int32),\n",
    "    reward= train['relevance'].values,\n",
    "    context= train[['user_idx']].merge(user_features, on='user_idx', how='left').drop(columns=['user_idx']).to_numpy(),\n",
    "    action_context= item_features.sort_values(by = ['item_idx']).drop(columns=['item_idx']).to_numpy(),\n",
    "    pscore = np.ones(train.shape[0]) # to write something that's unnecessary for get_est_rewards_by_reg \n",
    ")\n",
    "\n",
    "bandit_feedback_test = dict(\n",
    "    log=convert2spark(test),\n",
    "    item_features= convert2spark(item_features),\n",
    "    user_features= convert2spark(user_features),\n",
    "    n_rounds= test.shape[0],\n",
    "    n_actions= item_features.shape[0],\n",
    "    action = test['item_idx'].values,\n",
    "    position= np.zeros(test.shape[0]).astype(np.int32),\n",
    "    reward= test['relevance'].values,\n",
    "    context= test[['user_idx']].merge(user_features, on='user_idx', how='left').drop(columns=['user_idx']).to_numpy(),\n",
    "    action_context= item_features.sort_values(by = ['item_idx']).drop(columns=['item_idx']).to_numpy(),\n",
    "    pscore = np.ones(test.shape[0])  # to write something that's unnecessary for get_est_rewards_by_reg\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewards estimating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimated_rewards_by_reg_model = get_est_rewards_by_reg(bandit_feedback_train['n_actions'],\n",
    "                                                        1,\n",
    "                                                        bandit_feedback_train,\n",
    "                                                        bandit_feedback_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training bandits models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_1 = UCB(exploration_coef = 0.01, sample = True, seed = 123)\n",
    "learner_1 = OBPOfflinePolicyLearner(n_actions=bandit_feedback_train['n_actions'],\n",
    "                                    replay_model=model_1)\n",
    "\n",
    "model_2 = LinUCB(eps = -10, alpha = 10, is_hybrid=False)\n",
    "learner_2 = OBPOfflinePolicyLearner(n_actions=bandit_feedback_train['n_actions'],\n",
    "                                    replay_model=model_2)\n",
    "\n",
    "model_3 = RandomRec(distribution = 'relevance', alpha = 154.0, seed=42)\n",
    "learner_3 = OBPOfflinePolicyLearner(n_actions=bandit_feedback_train['n_actions'],\n",
    "                                    replay_model=model_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dist(learner):\n",
    "    all_action_dist = np.zeros((bandit_feedback_test[\"n_rounds\"], bandit_feedback_test[\"n_actions\"], 1))\n",
    "    if isinstance(learner.replay_model, (LinUCB)):\n",
    "        log_distinct = bandit_feedback_test['log'].toPandas().drop_duplicates(subset=[\"user_idx\"], keep='first')\n",
    "        users_all = bandit_feedback_test['log'].toPandas()['user_idx'].tolist()\n",
    "        batch_size = 10\n",
    "        num_batchs = log_distinct.shape[0] // batch_size\n",
    "        for batch_idx in tqdm(range(num_batchs+1)):\n",
    "            j = min((batch_idx+1)*batch_size, log_distinct.shape[0])\n",
    "            if j == batch_idx*batch_size:\n",
    "                break\n",
    "            log_subset = log_distinct.iloc[batch_idx*batch_size: j]\n",
    "            n_rounds = log_subset.shape[0]\n",
    "            \n",
    "            action_dist = learner.predict(n_rounds, convert2spark(log_subset).select('user_idx'))\n",
    "\n",
    "            users_distinct = log_subset['user_idx'].tolist()\n",
    "\n",
    "            user2ind = {}\n",
    "            for i in range(n_rounds):\n",
    "                user2ind[users_distinct[i]] = i\n",
    "\n",
    "            for i in range(bandit_feedback_test[\"n_rounds\"]):\n",
    "                if users_all[i] in users_distinct:\n",
    "                    all_action_dist[i] = action_dist[user2ind[users_all[i]]]\n",
    "\n",
    "    else:\n",
    "        batch_size = 300\n",
    "        num_batchs = bandit_feedback_test[\"n_rounds\"] // batch_size\n",
    "        for batch_idx in tqdm(range(num_batchs+1)):\n",
    "            j = min((batch_idx+1)*batch_size, bandit_feedback_test[\"n_rounds\"])\n",
    "            if j == batch_idx*batch_size:\n",
    "                break\n",
    "            bandit_feedback_subset = bandit_subset([batch_idx*batch_size, j], bandit_feedback_test) #The first parameter is a slice of subset [a, b]\n",
    "            action_dist = learner.predict(bandit_feedback_subset[\"n_rounds\"], bandit_feedback_subset[\"log\"].select('user_idx'))\n",
    "            all_action_dist[batch_idx*batch_size:j] = action_dist\n",
    "    return all_action_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner_1.fit(bandit_feedback_train)\n",
    "all_action_dist_1 = get_dist(learner_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner_2.fit(bandit_feedback_train)\n",
    "all_action_dist_2 = get_dist(learner_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner_3.fit(bandit_feedback_train)\n",
    "all_action_dist_3 = get_dist(learner_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute classic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner_1.predict_and_evaluate_new(bandit_feedback_test, K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner_2.predict_and_evaluate_new(bandit_feedback_test, K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner_3.predict_and_evaluate_new(bandit_feedback_test, K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(f'{name_dir}/UCB_policy', all_action_dist_1)\n",
    "np.save(f'{name_dir}/Lin_UCB_policy', all_action_dist_2)\n",
    "np.save(f'{name_dir}/Random_policy', all_action_dist_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_polices = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_train = post_log[['user_idx']].merge(user_features, on='user_idx', how='left').drop(columns=['user_idx']).to_numpy()\n",
    "action_train =  post_log['item_idx'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "size_subset = int(0.8*context_train.shape[0])\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': N_ITEMS,\n",
    "    'metric': 'multi_logloss',\n",
    "    'verbose': 1\n",
    "}\n",
    "behavior_policies = []\n",
    "cnt_skip = 0\n",
    "for i in range(num_polices):\n",
    "    print(i,\"start\")\n",
    "    bootstrap_idx = np.random.choice(context_train.shape[0], size=size_subset)\n",
    "    if np.unique(action_train[bootstrap_idx]).shape[0] != N_ITEMS:\n",
    "        cnt_skip += 1\n",
    "        continue\n",
    "    train_data = lgb.Dataset(context_train[bootstrap_idx], label=action_train[bootstrap_idx])\n",
    "    test_data = lgb.Dataset(bandit_feedback_test['context'][:10000], bandit_feedback_test['action'][:10000])\n",
    "    model = lgb.train(params,\n",
    "                  train_data,\n",
    "                  100,\n",
    "                  early_stopping_rounds=10,\n",
    "                  valid_sets=[test_data])\n",
    "    probs = model.predict(bandit_feedback_test['context'], num_iteration=model.best_iteration)\n",
    "    behavior_policies.append(probs[np.arange(bandit_feedback_test['action'].size), bandit_feedback_test['action']])\n",
    "behavior_policies_np = np.array(behavior_policies)\n",
    "np.save(f'{name_dir}/behavior_policies_lightgbm_25', behavior_policies_np)\n",
    "print('cnt skip:', cnt_skip) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LogReg with KL regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def CrossEntropyLoss_oh(pred, labels, kl_dist, alpha):\n",
    "    log_loss = torch.nn.functional.cross_entropy(pred,labels)\n",
    "    kl_reg = torch.mean(torch.sum((kl_dist * torch.log(kl_dist/torch.nn.functional.softmax(pred, dim=1))), dim=1))\n",
    "    return log_loss + alpha * kl_reg\n",
    "\n",
    "class my_Model(torch.nn.Module):\n",
    "    def __init__(self,cnt_feat, num_classes):\n",
    "        super().__init__()\n",
    "        self.lin = torch.nn.Sequential(\n",
    "            torch.nn.Linear(cnt_feat, num_classes, bias=True)           \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "class Behavior_Clone_Model:\n",
    "    def __init__(self, cnt_feat, num_classes, lr, n_epochs, batch_size, alpha):\n",
    "        self.n_epochs = n_epochs  # epochs\n",
    "        self.lr = lr  # learning rate\n",
    "        self.batch_size = batch_size #batch_size\n",
    "        self.alpha = alpha #param of regul\n",
    "        # model\n",
    "        self.model = my_Model(cnt_feat, num_classes)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def fit(self, x_train, Y_train, x_test, Y_test):\n",
    "        # training graph and optimization\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        # loss and accuracy storage\n",
    "        cnt_batch_per_epoch = Y_train.size//self.batch_size\n",
    "        self.model.train()\n",
    "        for epoch in range(self.n_epochs*cnt_batch_per_epoch + 1):\n",
    "            # randomic batch definition\n",
    "            rbatch = np.random.choice(Y_train.size, size=self.batch_size)\n",
    "            # variables initialization\n",
    "            X = torch.autograd.Variable(torch.FloatTensor(x_train[rbatch]))\n",
    "            Y = torch.LongTensor(Y_train[rbatch].astype(np.int))\n",
    "            dist_batch = torch.FloatTensor(np.ones((self.batch_size, self.num_classes))* (1/self.num_classes))\n",
    "            # training, metrics and storage\n",
    "            optimizer.zero_grad()\n",
    "            pred = self.model(X)\n",
    "            L = CrossEntropyLoss_oh(pred, Y, dist_batch, self.alpha)\n",
    "            L.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch%1000 == 0:\n",
    "                self.model.eval()\n",
    "                with torch.no_grad():\n",
    "                    X_ = torch.autograd.Variable(torch.FloatTensor(x_test))\n",
    "                    pred_test = self.model(X_)\n",
    "                    Y_ = torch.LongTensor(Y_test)\n",
    "                    dist_test = torch.FloatTensor(np.ones((Y_.shape[0], self.num_classes))* (1/self.num_classes))\n",
    "                    loss_test = CrossEntropyLoss_oh(pred_test, Y_, dist_test, self.alpha)\n",
    "                    print('epoch', epoch, 'ce_loss_test: ', loss_test.detach())\n",
    "                print('epoch: {0:04d} | loss: {1:.3f}'.format(epoch, L))\n",
    "                self.model.train()\n",
    "    \n",
    "    def predict_proba(self, x_test, Y_test):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_ = torch.autograd.Variable(torch.FloatTensor(x_test))\n",
    "            probs = torch.nn.functional.softmax(self.model(X_), dim=1).detach().numpy()\n",
    "        print('acc: ',(np.argmax(probs, axis = 1) == Y_test).mean())\n",
    "        return probs[np.arange(Y_test.size), Y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size_subset = int(0.8*context_train.shape[0])\n",
    "cnt_skip = 0\n",
    "for alpha in [0, 10, 70]:\n",
    "    behavior_policies = []\n",
    "    print(alpha, 'start')\n",
    "    for i in range(num_polices):\n",
    "        print(i,\"start\")\n",
    "        bootstrap_idx = np.random.choice(context_train.shape[0], size=size_subset)\n",
    "        if np.unique(action_train[bootstrap_idx]).shape[0] != N_ITEMS:\n",
    "            cnt_skip += 1\n",
    "            continue\n",
    "        b_model = Behavior_Clone_Model(context_train.shape[1], bandit_feedback_train['n_actions'], 1e-4, 20, 64, alpha)\n",
    "        b_model.fit(context_train[bootstrap_idx], action_train[bootstrap_idx], bandit_feedback_test['context'][:10000], bandit_feedback_test['action'][:10000])\n",
    "        behavior_policies.append(b_model.predict_proba(bandit_feedback_test['context'], bandit_feedback_test['action']))\n",
    "    behavior_policies_np = np.array(behavior_policies)\n",
    "    np.save(f'{name_dir}/behavior_policies_log_reg_25_alpha={alpha}', behavior_policies_np)\n",
    "print('cnt_skip', cnt_skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute viewed items for users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "viewed_items = bandit_feedback_train[\"log\"].toPandas().groupby(\"user_idx\", sort=True)[\"item_idx\"].apply(list)\n",
    "viewed_items_all = { i: viewed_items[i] if i in viewed_items.index else [] for i in range(N_USERS)}\n",
    "viewed_items_for_test = [viewed_items_all[item_idx] for item_idx in bandit_feedback_test['log'].toPandas()['user_idx'].values]\n",
    "viewed_items_for_test = np.array(viewed_items_for_test)\n",
    "viewed_items_for_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Offpolicy methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ipw(pi_e, pi_0, r, r_hat):\n",
    "    weights = pi_e/pi_0\n",
    "    return weights * r\n",
    "\n",
    "def snipw(pi_e, pi_0, r, r_hat):\n",
    "    weights = pi_e/pi_0\n",
    "    weights = weights/weights.mean()\n",
    "    return weights * r\n",
    "    \n",
    "def sndr(pi_e, pi_0, r, r_hat, dm):\n",
    "    weights = pi_e/pi_0\n",
    "    weights = weights/weights.mean()\n",
    "    return dm + weights*(r-r_hat)\n",
    "\n",
    "def dm(dm):\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_action_dist_1 = np.load(f\"{name_dir}/UCB_policy.npy\")\n",
    "all_action_dist_2 = np.load(f\"{name_dir}/Lin_UCB_policy.npy\")\n",
    "all_action_dist_3 = np.load(f\"{name_dir}/Random_policy.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute r_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r_hat = estimated_rewards_by_reg_model[np.arange(bandit_feedback_test['action'].shape[0]), bandit_feedback_test['action'], 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter viewed items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_action_dist_1_new = all_action_dist_1.copy()\n",
    "for i in range(all_action_dist_1.shape[0]):\n",
    "    all_action_dist_1_new[i][viewed_items_for_test[i]] = 0\n",
    "    all_action_dist_1_new[i]/= all_action_dist_1_new[i].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_action_dist_2_new = all_action_dist_2.copy()\n",
    "for i in range(all_action_dist_2.shape[0]):\n",
    "    all_action_dist_2_new[i][viewed_items_for_test[i]] = 0\n",
    "    all_action_dist_2_new[i]/= all_action_dist_2_new[i].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_action_dist_3_new = all_action_dist_3.copy()\n",
    "for i in range(all_action_dist_3.shape[0]):\n",
    "    all_action_dist_3_new[i][viewed_items_for_test[i]] = 0\n",
    "    all_action_dist_3_new[i]/= all_action_dist_3_new[i].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_action_dist_1_top_10 = all_action_dist_1_new.copy()\n",
    "idx_1 = np.argsort(-all_action_dist_1_top_10, axis = 1)\n",
    "for i in range(all_action_dist_1_top_10.shape[0]):\n",
    "    all_action_dist_1_top_10[i][idx_1[i][10:]] = 0\n",
    "    all_action_dist_1_top_10[i] /= all_action_dist_1_top_10[i].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_action_dist_2_top_10 = all_action_dist_2_new.copy()\n",
    "idx_2 = np.argsort(-all_action_dist_2_top_10, axis = 1)\n",
    "for i in range(all_action_dist_2_top_10.shape[0]):\n",
    "    all_action_dist_2_top_10[i][idx_2[i][10:]] = 0\n",
    "    all_action_dist_2_top_10[i] /= all_action_dist_2_top_10[i].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_action_dist_3_top_10 = all_action_dist_3_new.copy()\n",
    "idx_3 = np.argsort(-all_action_dist_3_top_10, axis = 1)\n",
    "for i in range(all_action_dist_3_top_10.shape[0]):\n",
    "    all_action_dist_3_top_10[i][idx_3[i][10:]] = 0\n",
    "    all_action_dist_3_top_10[i] /= all_action_dist_3_top_10[i].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_method_1 = (estimated_rewards_by_reg_model * all_action_dist_1).sum(axis = 1).squeeze()\n",
    "DM_method_2 = (estimated_rewards_by_reg_model * all_action_dist_2).sum(axis = 1).squeeze()\n",
    "DM_method_3 = (estimated_rewards_by_reg_model * all_action_dist_3).sum(axis = 1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DM_method_1_new = (estimated_rewards_by_reg_model * all_action_dist_1_new).sum(axis = 1).squeeze()\n",
    "DM_method_2_new = (estimated_rewards_by_reg_model * all_action_dist_2_new).sum(axis = 1).squeeze()\n",
    "DM_method_3_new = (estimated_rewards_by_reg_model * all_action_dist_3_new).sum(axis = 1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DM_method_1_top_10 = (estimated_rewards_by_reg_model * all_action_dist_1_top_10).sum(axis = 1).squeeze()\n",
    "DM_method_2_top_10 = (estimated_rewards_by_reg_model * all_action_dist_2_top_10).sum(axis = 1).squeeze()\n",
    "DM_method_3_top_10 = (estimated_rewards_by_reg_model * all_action_dist_3_top_10).sum(axis = 1).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute TV distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_log = post_log.copy()\n",
    "# new_log = new_log.iloc[bootstrap_idx]\n",
    "new_test_log = bandit_feedback_test['log'].toPandas().copy()\n",
    "frequency = new_log.groupby(['user_idx', 'item_idx']).size().reset_index(name='frequency')\n",
    "\n",
    "# Шаг 2: Считаем сумму всех частот для каждого user\n",
    "frequency['total_frequency'] = frequency.groupby('user_idx')['frequency'].transform('sum')\n",
    "\n",
    "# Шаг 3: Нормируем частоты\n",
    "frequency['normalized_frequency'] = frequency['frequency'] / frequency['total_frequency']\n",
    "frac_dist_test = [frequency[(frequency['user_idx'] == new_test_log.iloc[i]['user_idx'])&(frequency['item_idx'] == new_test_log.iloc[i]['item_idx'])]['normalized_frequency'].values[0] for i in range(new_test_log.shape[0])]\n",
    "frac_dist_test = np.array(frac_dist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_dist_test = np.ones(bandit_feedback_test['action'].shape[0])/N_ITEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_log =post_log.copy()\n",
    "map_pop_dist = new_log['item_idx'].value_counts(normalize=True)\n",
    "pop_dist = map_pop_dist.loc[new_log['item_idx'].values].values\n",
    "pop_dist_test = map_pop_dist.loc[bandit_feedback_test['action']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "behavior_policies_1 = #TODO #Here we define behavioral policies learned on different subsets  ex: np.load(f'{name_dir}/behavior_policies_lightgbm_25.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tv_random = []\n",
    "tv_pop = []\n",
    "tv_frac = []\n",
    "tv_pair = []\n",
    "for i in range(num_polices):\n",
    "    tv_random.append((np.abs(behavior_policies_1[i] - random_dist_test)).sum()/600)\n",
    "    tv_pop.append((np.abs(behavior_policies_1[i] - pop_dist_test)).sum()/600)\n",
    "    tv_frac.append((np.abs(behavior_policies_1[i] - frac_dist_test)).sum()/600)\n",
    "    for j in range(i, num_polices):\n",
    "        tv_pair.append((np.abs(behavior_policies_1[i] - behavior_policies_1[j])).sum()/600)\n",
    "print(f'TV random={np.mean(tv_random)}')\n",
    "print(f'TV popular={np.mean(tv_pop)}')\n",
    "print(f'TV frequency={np.mean(tv_frac)}')\n",
    "print(f'TV pairwise={np.mean(tv_pair)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute offpolicy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_exp(all_action_dist, DM_method):\n",
    "    metrics = ['ipw', 'snipw', 'sndr', 'dm']\n",
    "    pi_e = all_action_dist[np.arange(bandit_feedback_test['action'].shape[0]), bandit_feedback_test['action'], 0].copy()\n",
    "    cnt_inner_bootstraps = 100\n",
    "    _alpha = 0.05\n",
    "    CIs = []\n",
    "    for n_size in [10000, 20000, 50000, 70000, 94124]:\n",
    "        res = {}\n",
    "        pi_e_subset = pi_e[:n_size].copy()\n",
    "        r_hat_subset = r_hat[:n_size].copy()\n",
    "        r_subset = bandit_feedback_test['reward'][:n_size].copy()\n",
    "        dm_subset = DM_method[:n_size].copy()\n",
    "        stats = {}\n",
    "        print(n_size)\n",
    "        for metric in metrics:\n",
    "            stats[metric] = []\n",
    "        behavior_policies =  #TODO #Here we define behavioral policies learned on different subsets  ex: np.load(f'{name_dir}/behavior_policies_lightgbm_25.npy')\n",
    "        for i in range(num_polices):\n",
    "            pi_0_subset= behavior_policies[i][:n_size]\n",
    "            ipw_est_round_rewards = ipw(pi_e_subset, pi_0_subset, r_subset, r_hat_subset)\n",
    "            snipw_est_round_rewards = snipw(pi_e_subset, pi_0_subset, r_subset, r_hat_subset)\n",
    "            sndr_est_round_rewards = sndr(pi_e_subset, pi_0_subset, r_subset, r_hat_subset, dm_subset)\n",
    "            dm_est_round_rewards = dm(dm_subset)\n",
    "\n",
    "            for j in range(cnt_inner_bootstraps):\n",
    "                bootstrap_idxs = np.random.randint(n_size, size=n_size)\n",
    "                stats['ipw'].append(ipw_est_round_rewards[bootstrap_idxs].mean())\n",
    "                stats['snipw'].append(snipw_est_round_rewards[bootstrap_idxs].mean())\n",
    "                stats['sndr'].append(sndr_est_round_rewards[bootstrap_idxs].mean())\n",
    "                stats['dm'].append(dm_est_round_rewards[bootstrap_idxs].mean())\n",
    "        for metric in metrics:\n",
    "            dct = {}\n",
    "            values = stats[metric]\n",
    "            dct['mean'] = np.mean(values)\n",
    "            dct['95.0% CI (lower)'] = np.percentile(values, 100 * (_alpha / 2))\n",
    "            dct['95.0% CI (upper)'] = np.percentile(values, 100 * (1.0 - _alpha / 2))\n",
    "            res[metric] = dct\n",
    "        CIs.append(res)\n",
    "    return CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CIs_1 = run_exp(all_action_dist_1_top_10, DM_method_1_top_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CIs_2 = run_exp(all_action_dist_2_top_10, DM_method_2_top_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CIs_3 = run_exp(all_action_dist_3_top_10, DM_method_3_top_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_CIs(CIs_1, CIs_2, CIs_3, model_1, model_2, model_3):\n",
    "    fig, ax = plt.subplots(4, figsize=(10, 10))\n",
    "    \n",
    "    x = [10000, 20000, 50000, 70000, 94124]\n",
    "\n",
    "    colors = ['b', 'r', 'g', 'y']\n",
    "    i = 0 \n",
    "    for name in ['ipw', 'dm', 'sndr', 'snipw']:\n",
    "        y_est = [estimated_ci[name][\"mean\"] for estimated_ci in CIs_1]\n",
    "        y_up = [estimated_ci[name][\"95.0% CI (upper)\"] for estimated_ci in CIs_1]\n",
    "        y_low = [estimated_ci[name][\"95.0% CI (lower)\"] for estimated_ci in CIs_1]\n",
    "        \n",
    "        ax[i].plot(x, y_est, '-', label=model_1, color = colors[0])\n",
    "        ax[i].fill_between(x, y_low, y_up, alpha=0.2, color = colors[0])\n",
    "        \n",
    "        y_est = [estimated_ci[name][\"mean\"] for estimated_ci in CIs_2]\n",
    "        y_up = [estimated_ci[name][\"95.0% CI (upper)\"] for estimated_ci in CIs_2]\n",
    "        y_low = [estimated_ci[name][\"95.0% CI (lower)\"] for estimated_ci in CIs_2]\n",
    "        \n",
    "        ax[i].plot(x, y_est, '-', label=model_2, color = colors[1])\n",
    "        ax[i].fill_between(x, y_low, y_up, alpha=0.2, color = colors[1])\n",
    "        \n",
    "        y_est = [estimated_ci[name][\"mean\"] for estimated_ci in CIs_3]\n",
    "        y_up = [estimated_ci[name][\"95.0% CI (upper)\"] for estimated_ci in CIs_3]\n",
    "        y_low = [estimated_ci[name][\"95.0% CI (lower)\"] for estimated_ci in CIs_3]\n",
    "        \n",
    "        ax[i].plot(x, y_est, '-', label=model_3, color = colors[2])\n",
    "        ax[i].fill_between(x, y_low, y_up, alpha=0.2, color = colors[2])\n",
    "        \n",
    "        ax[i].set_title(name)\n",
    "        i+=1\n",
    "\n",
    "    fig.suptitle(\"OPE for \" + \" \" + model_1 + \" \" + model_2 + \" \" + model_3, fontsize=16)\n",
    "    fig.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_CIs(CIs_1,CIs_2, CIs_3, 'UCB', 'Lin_UCB', 'Random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OBD library "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To use the obd library, we must define bandit_feedback_test['pscore']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit_feedback_test['pscore'] = #TODO #Here we define behavioral policie learned on ONE subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def run_exp_obd(learner_action_dist, lambda_, beta_1, beta_2):\n",
    "    Vs = []\n",
    "    CIs = []\n",
    "    subsets = [10000, 20000, 50000, 70000, 94124]\n",
    "        \n",
    "    for n_size in subsets:\n",
    "        start = time.time()\n",
    "        bandit_feedback_subset = bandit_subset([0, n_size], bandit_feedback_test) #The first parameter is a slice of subset [a, b]\n",
    "\n",
    "        ope = OffPolicyEvaluation(\n",
    "            bandit_feedback=bandit_feedback_subset,\n",
    "            ope_estimators=[InverseProbabilityWeighting(), DirectMethod(), SelfNormalizedDoublyRobust(),\n",
    "                            SelfNormalizedInverseProbabilityWeighting(),\n",
    "                            Exp_Smooth_IPS_Max(beta = beta_1), Exp_Smooth_IPS_Min(beta = beta_2), InverseProbabilityWeighting(lambda_ = lambda_, estimator_name='cips')]\n",
    "        )\n",
    "\n",
    "        estimated_rewards_by_reg_model_subset = estimated_rewards_by_reg_model[0: n_size, :]\n",
    "        \n",
    "        action_dist = learner_action_dist[:n_size, :]\n",
    "        estimated_policy_value = ope.estimate_policy_values(\n",
    "            action_dist=action_dist,\n",
    "            estimated_rewards_by_reg_model=estimated_rewards_by_reg_model_subset,\n",
    "        )\n",
    "\n",
    "        estimated_ci = ope.estimate_intervals(\n",
    "            action_dist=action_dist,\n",
    "            estimated_rewards_by_reg_model=estimated_rewards_by_reg_model_subset,\n",
    "            n_bootstrap_samples=100,\n",
    "            random_state=12345,)\n",
    "        end = time.time()\n",
    "        print(\"n_size =\", n_size, \"time: \", end-start)\n",
    "        Vs.append(estimated_policy_value)\n",
    "        CIs.append(estimated_ci)\n",
    "    return(Vs, CIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize parametrs of offpolicy methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_ope_parameters(learner_action_dist, lambda_s, beta_1s, beta_2s, k=10000):\n",
    "    CIPS_MSE = []\n",
    "    for lambda_ in lambda_s:\n",
    "        ope = InverseProbabilityWeighting(lambda_=lambda_, estimator_name='cips')\n",
    "        CIPS_MSE.append(ope._estimate_mse_score(\n",
    "            reward=bandit_feedback_test['reward'][:k],\n",
    "            action=bandit_feedback_test['action'][:k],\n",
    "            pscore=bandit_feedback_test['pscore'][:k],\n",
    "            action_dist=learner_action_dist[:k],\n",
    "            position=bandit_feedback_test['position'][:k],\n",
    "            use_bias_upper_bound = False))\n",
    "        best_idx = np.argmin(np.array(CIPS_MSE))\n",
    "        best_lambda_ = lambda_s[best_idx]\n",
    "    \n",
    "    ESIPSMAX_MSE = []\n",
    "    for beta_1 in beta_1s:\n",
    "        ope = Exp_Smooth_IPS_Max(beta = beta_1)\n",
    "        ESIPSMAX_MSE.append(ope._estimate_mse_score(\n",
    "            reward=bandit_feedback_test['reward'][:k],\n",
    "            action=bandit_feedback_test['action'][:k],\n",
    "            pscore=bandit_feedback_test['pscore'][:k],\n",
    "            action_dist=learner_action_dist[:k],\n",
    "            position=bandit_feedback_test['position'][:k],\n",
    "            use_bias_upper_bound = False))\n",
    "        best_idx = np.argmin(np.array(ESIPSMAX_MSE))\n",
    "        best_beta_1 = beta_1s[best_idx]\n",
    "        \n",
    "    ESIPSMIN_MSE = []\n",
    "    for beta_2 in beta_2s:\n",
    "        ope = Exp_Smooth_IPS_Min(beta = beta_2)\n",
    "        ESIPSMIN_MSE.append(ope._estimate_mse_score(\n",
    "            reward=bandit_feedback_test['reward'][:k],\n",
    "            action=bandit_feedback_test['action'][:k],\n",
    "            pscore=bandit_feedback_test['pscore'][:k],\n",
    "            action_dist=learner_action_dist[:k],\n",
    "            position=bandit_feedback_test['position'][:k],\n",
    "            use_bias_upper_bound = False))\n",
    "        best_idx = np.argmin(np.array(ESIPSMIN_MSE))\n",
    "        best_beta_2 = beta_2s[best_idx]\n",
    "        \n",
    "    return {'lambda_':best_lambda_, 'beta_1': best_beta_1, 'beta_2': best_beta_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_opt_algo = {    \n",
    "    'UCB': {'lambda_s': [1, 1.2, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 5, 6, 7, 8, 9, 9.5, 9.6, 9.7, 9.8, 9.9, 50, 55, 60, 65, 70, 71, 75, 79, np.inf], \n",
    "                 'beta_1s': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.98, 0.99, 1], \n",
    "                 'beta_2s': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.98, 0.99, 1]},\n",
    "    \n",
    "    'LinUCB': {'lambda_s': [1, 1.2, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 5, 6, 7, 8, 9, 9.5, 9.6, 9.7, 9.8, 9.9, 50, 55, 60, 65, 70, 71, 75, 79, np.inf], \n",
    "                 'beta_1s': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.98, 0.99, 1], \n",
    "                 'beta_2s': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.98, 0.99, 1]},\n",
    "    \n",
    "    'Random': {'lambda_s': [1, 1.2, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 5, 6, 7, 8, 9, 9.5, 9.6, 9.7, 9.8, 9.9, 50, 55, 60, 65, 70, 71, 75, 79, np.inf], \n",
    "                 'beta_1s': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.98, 0.99, 1], \n",
    "                 'beta_2s': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.98, 0.99, 1]},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_action_dist_1 = all_action_dist_1_top_10\n",
    "learner_action_dist_2 = all_action_dist_2_top_10\n",
    "learner_action_dist_3 = all_action_dist_3_top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_ips_1 = optimize_ope_parameters(learner_action_dist_1, dict_opt_algo['UCB']['lambda_s'], dict_opt_algo['UCB']['beta_1s'], dict_opt_algo['UCB']['beta_2s'])\n",
    "print(opt_params_ips_1)\n",
    "Vs_1, CIs_1_obd = run_exp_obd(learner_action_dist_1, opt_params_ips_1['lambda_'], opt_params_ips_1['beta_1'], opt_params_ips_1['beta_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt_params_ips_2 = optimize_ope_parameters(learner_action_dist_2, dict_opt_algo['LinUCB']['lambda_s'], dict_opt_algo['LinUCB']['beta_1s'], dict_opt_algo['LinUCB']['beta_2s'])\n",
    "print(opt_params_ips_2)\n",
    "Vs_2, CIs_2_obd = run_exp_obd(learner_action_dist_2, opt_params_ips_2['lambda_'], opt_params_ips_2['beta_1'], opt_params_ips_2['beta_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt_params_ips_3 = optimize_ope_parameters(learner_action_dist_3, dict_opt_algo['Random']['lambda_s'], dict_opt_algo['Random']['beta_1s'], dict_opt_algo['Random']['beta_2s'])\n",
    "print(opt_params_ips_3)\n",
    "Vs_3, CIs_3_obd = run_exp_obd(learner_action_dist_3, opt_params_ips_3['lambda_'], opt_params_ips_3['beta_1'], opt_params_ips_3['beta_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_CIs_obd(CIs_1, CIs_2, CIs_3, model_1, model_2, model_3):\n",
    "    fig, ax = plt.subplots(7, figsize=(10, 20))\n",
    "    \n",
    "    x = [10000, 20000, 50000, 70000, 94124]\n",
    "\n",
    "    colors = ['b', 'r', 'g', 'y',  'aqua', 'pink', 'orange']\n",
    "    i = 0 \n",
    "    for name in ['ipw', 'dm', 'sndr', 'snipw', 'ESIPSMAX',  'ESIPSMIN', 'cips']:\n",
    "        y_est = [estimated_ci[name][\"mean\"] for estimated_ci in CIs_1]\n",
    "        y_up = [estimated_ci[name][\"95.0% CI (upper)\"] for estimated_ci in CIs_1]\n",
    "        y_low = [estimated_ci[name][\"95.0% CI (lower)\"] for estimated_ci in CIs_1]\n",
    "        \n",
    "        ax[i].plot(x, y_est, '-', label=model_1, color = colors[0])\n",
    "        ax[i].fill_between(x, y_low, y_up, alpha=0.2, color = colors[0])\n",
    "        \n",
    "        y_est = [estimated_ci[name][\"mean\"] for estimated_ci in CIs_2]\n",
    "        y_up = [estimated_ci[name][\"95.0% CI (upper)\"] for estimated_ci in CIs_2]\n",
    "        y_low = [estimated_ci[name][\"95.0% CI (lower)\"] for estimated_ci in CIs_2]\n",
    "        \n",
    "        ax[i].plot(x, y_est, '-', label=model_2, color = colors[1])\n",
    "        ax[i].fill_between(x, y_low, y_up, alpha=0.2, color = colors[1])\n",
    "        \n",
    "        y_est = [estimated_ci[name][\"mean\"] for estimated_ci in CIs_3]\n",
    "        y_up = [estimated_ci[name][\"95.0% CI (upper)\"] for estimated_ci in CIs_3]\n",
    "        y_low = [estimated_ci[name][\"95.0% CI (lower)\"] for estimated_ci in CIs_3]\n",
    "        \n",
    "        ax[i].plot(x, y_est, '-', label=model_3, color = colors[2])\n",
    "        ax[i].fill_between(x, y_low, y_up, alpha=0.2, color = colors[2])\n",
    "        \n",
    "        ax[i].set_title(name)\n",
    "        i+=1\n",
    "\n",
    "    fig.suptitle(\"OPE for \" + \" \" + model_1 + \" \" + model_2 + \" \" + model_3, fontsize=16)\n",
    "    fig.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_CIs_obd(CIs_1_obd, CIs_2_obd, CIs_3_obd, 'UCB', 'LinUCB', 'Random')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
